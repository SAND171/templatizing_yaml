## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
cp-zookeeper:
  enabled: true
  servers: 1
  image:
    repository: confluentinc/cp-zookeeper
    tag: 6.2.0
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  persistence:
    enabled: true
    ## The size of the PersistentVolume to allocate to each Zookeeper Pod in the StatefulSet. For
    ## production servers this number should likely be much larger.
    ##
    ## Size for Data dir, where ZooKeeper will store the in-memory database snapshots.
    dataDirSize: 50Gi
    # dataDirStorageClass: ""

    ## Size for data log dir, which is a dedicated log device to be used, and helps avoid competition between logging and snaphots.
    dataLogDirSize: 50Gi
    # dataLogDirStorageClass: ""
  resources: {}
  securityContext: 
    runAsUser: 0
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

## ------------------------------------------------------
## Kafka
## ------------------------------------------------------
cp-kafka:
  enabled: true
  replicas: 3
  image: confluentinc/cp-kafka
  imageTag: 6.2.0
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx1024M"
  persistence:
    enabled: true
    # storageClass: ""
    size: 500Gi
    disksPerBroker: 1
  resources: {}
  securityContext: 
    runAsUser: 0
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi
  configurationOverrides:
    "offsets.topic.replication.factor": "3"
    "default.replication.factor": 3
    # "min.insync.replicas": 2
    "transaction.max.timeout.ms": "3600000"

## ------------------------------------------------------
## Schema Registry
## ------------------------------------------------------
cp-schema-registry:
  enabled: true
  image: confluentinc/cp-schema-registry
  imageTag: 6.2.0
  nodePort: 30081
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi


## ------------------------------------------------------
## Kafka Connect
## ------------------------------------------------------
cp-kafka-connect:
  enabled: true
  image:
    repository: gcr.io/izackubernetes/izac/master/kafkaconnect
    tag: e063df27a0faf52e3008b024010c87bac801356c
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  nodePort:  30083
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi
  configurationOverrides:
    "plugin.path": "/usr/share/java,/usr/share/confluent-hub-components"
    "key.converter": "io.confluent.connect.avro.AvroConverter"
    "value.converter": "io.confluent.connect.avro.AvroConverter"
    "key.converter.schemas.enable": "false"
    "value.converter.schemas.enable": "false"
    "internal.key.converter": "org.apache.kafka.connect.json.JsonConverter"
    "internal.value.converter": "org.apache.kafka.connect.json.JsonConverter"
    "config.storage.replication.factor": "1"
    "offset.storage.replication.factor": "1"
    "status.storage.replication.factor": "1"


consumeroffsetmonitoring:
  enabled: true
  image:
    repository: whiteklay/consumeroffsetsmonitoring
    tag: latest
  kafka:
    consumerOffsetsOutputTopic: consumerOffsetsTest3
    offsetConsumerClientID: Kafka_ConsumerOffsets_Monitor
    offsetConsumerGroupID: consumer-offset
    numberOfRecordsToCommit: 5


eventview:
  enabled: true
  image:
    repository: gcr.io/izackubernetes/izac/master/eventview
    tag: e063df27a0faf52e3008b024010c87bac801356c
  kafka:
    metadataMaxAgeMs: 300000
    consumerGroupID: eventview
  service:
    enabled: true
    httpPort: 80
    nodePort: 32074
    type: NodePort

kafkaadmin:
  enabled: true
  image:
    repository: gcr.io/izackubernetes/izac/master/kafkaadmin
    tag: e063df27a0faf52e3008b024010c87bac801356c
  kafka:
    kafkaConsumerGroupIDAdmin: kafkaAdmin
  service:
    enabled: true
    httpPort: 80
    nodePort: 32073
    type: NodePort

metadata:
  enabled: true
  image:
    repository: gcr.io/izackubernetes/izac/master/metadata
    tag: e063df27a0faf52e3008b024010c87bac801356c
  schemaSubjectNamePrefix: metadata
  service:
    enabled: true
    httpPort: 80
    nodePort: 32072
    type: NodePort



joblauncherspark:
  replicationaCount: 1
  image:
    repository: whiteklay/joblauncherspark
    tag: latest
    pullPolicy: IfNotPresent
  kafka:
    consumergroupid: joblauncherspark
    sparkflowjobqueuetopic: joblauncherspark
  sparkflowimagewithtag: ilanosortap/izac:latest
  SPARK_FLOW_MAIN_APPLICATION_FILE: "local:///opt/spark/examples/jars/izac-distribution-assembly-1.4-Alpha2.jar"



jobserver:
  replicaCount: 1
  image:
    repository: gcr.io/izackubernetes/izac/master/jobserver
    tag: e063df27a0faf52e3008b024010c87bac801356c
    pullPolicy: IfNotPresent
  kafka:
    jobqueuetopic: jobqueue
    SPARK_FLOW_JOB_QUEUE_TOPIC: joblauncherspark
  springContextPath: "/jobserver"
  images:
    flowimagewithtag: whiteklay/flowkafkastreams:latest
    profileimagewithtag: whiteklay/profilekafkastreams:latest


queryconsumeroffsets:
  replicaCount: 1
  image:
    repository: gcr.io/izackubernetes/izac/master/queryconsumeroffsets
    tag: e063df27a0faf52e3008b024010c87bac801356c
    pullPolicy: IfNotPresent
  kafka:
    OFFSET_CONSUMER_GROUP_ID: consumer-offset3
    CONSUMER_OFFSETS_OUTPUT_TOPIC: consumerOffsetsTest3
    AUTO_OFFSET_RESET_CONFIG: earliest
  springContextPath: "/queryconsumeroffsets"


mysql:
  enabled: true

postgresql:
  enabled: true

superset:
  enabled: true

## ------------------------------------------------------
## REST Proxy
## ------------------------------------------------------
cp-kafka-rest:
  enabled: true
  image: confluentinc/cp-kafka-rest
  imageTag: 5.5.0
  ## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
  ## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  imagePullSecrets:
  #  - name: "regcred"
  heapOptions: "-Xms512M -Xmx512M"
  resources: {}
  ## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
  ## and remove the curly braces after 'resources:'
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

flow-utils:
  replicaCount: 1
  image:
    repository: prohankumar/flow-utils
    tag: "cb516b9cd0e44e60d0d84ad3ac2ab90afc48f284"
  jarBuildingJob:
    image: prohankumar/flow_utils_jar_building:6
  kafka:
    external: false
    address: PLAINTEXT://izac-cp-kafka-headless:9092
  schemaRegistry:
    external: false
    address: http://izac-cp-schema-registry:8081
  flowJob:
    image: prohankumar/flow:cb516b9cd0e44e60d0d84ad3ac2ab90afc48f284
    serviceAccountName: flow-sa
    namespace: default
    flinkBucket: s3p://izac-flink
    flowConfigs: "{}"
    stateStore:
      endpoint: http://10.10.10.33:32727
      accessKey: minio
      secretKey: minio123
  flowServer:
    containerName: flow-server
    args: ["com.whiteklay.flow.flink.FlowRequestServer"]
    service:
      port: 8080
      targetPort: 50051
  flowRequestProcessor:
    containerName: flow-request-processor
    args: ["com.whiteklay.flow.flink.FlowRequestProcessor"]
  flowFlinkJobSubmitter:
    containerName: flow-flink-job-submitter
    args: ["com.whiteklay.flow.flink.SubmitFlowJob"]
  


flow-validator:
  replicaCount: 1
  image:
    repository: prohankumar/flow-validator
    tag: "cb516b9cd0e44e60d0d84ad3ac2ab90afc48f284"
  kafka:
    external: false
    address: ""
  schemaRegistry:
    external: false
    address: ""
  flowConfigs: "{}"
  service:
    type: NodePort
    port: 80
    targetPort: 50051


profile-kafka-to-postgres:
  image:
    repository: ytrg10/kafka-to-postgres
    tag: 1.0.1
  envVariables:
    postgresServer: izac-postgresql-headless:5432
    database: profilemetrics
    username: postgres
    password: postgrespwd
    table: metrics
    outputTopic: profile-test-1
    groupId: profile-kafka-to-postgres
  kafka:
    external: false
    address: PLAINTEXT://izac-cp-kafka-headless:9092
    CONSUMER_PROPERTIES: '{}'

  schemaRegistry:
    external: true
    address: http://izac-cp-schema-registry:8081


profile-metrics-api:
  image:
    repository: ytrg10/profile_metrics_api
    tag: 1.0.3
  envVariables:
    postgresServer: izac-postgresql-headless:5432
    database: profilemetrics
    username: postgres
    password: postgrespwd
    table: metrics
